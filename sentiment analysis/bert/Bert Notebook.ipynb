{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwcxV72--dSZ",
    "outputId": "12906bb8-1c09-459c-982e-7742718eaefa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UJ9_034--067"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_datasets(base_dir='/content/drive/MyDrive/text_analysis/datasets'):\n",
    "    \"\"\"\n",
    "    Load train, validation and test datasets\n",
    "    Return all three datasets\n",
    "    \"\"\"\n",
    "    # Define file paths\n",
    "    train_path = os.path.join(base_dir, \"train_drug_reviews2.csv\")\n",
    "    val_path = os.path.join(base_dir, \"val_drug_reviews2.csv\")\n",
    "    test_path = os.path.join(base_dir, \"test_drug_reviews2.csv\")\n",
    "\n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    val_df = pd.read_csv(val_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8aa78f41b5194dd791a073c892c3bad1",
      "0804f1c600bc4cf5832b394149c4e560",
      "bf143d7fa2f140d8b7ac8b85a85d8231",
      "8a43d8db896444c6ab4b7d5b881e804b",
      "7f77e4abc6d844a1b2ca582ff71dd3e1",
      "b0494803d10e4097823aca85d4f40186",
      "9f37e28c1bba4eaa8e3793573e45cdae",
      "ccd72515cd8f4936aa0a86b051f2e65c",
      "3cbe715b2d0f410f89c91c18f737ca98",
      "5c01760a89844a0abf3f7879b96fb8af",
      "90199ad5ea9c4c27acff500f2fc2699b",
      "ddb2d45923344e76853d392a2c254130",
      "5bf83774eb97475bafb30bbbbd7b62b6",
      "d9f7921c1280435a957d5c4ed6b293ec",
      "f4d49a9063324385a2470fe6b652f439",
      "748070220fba41e98ca66bcb0b433997",
      "383f11dd9e0643e9a0e4238499dd0fc5",
      "3c96119d7e3b4969af5d555f1aaf4988",
      "54b90a28ef75450a8508e5ee914ce1c4",
      "f6c47c46c9044cd88f4c18e0a2fd2b95",
      "41ba3ea00b03450f9ec421d11c5677ed",
      "576ce0fa13794cd599590361f3afd1bd",
      "ec4253643cb845428044fb3ea8dc6e96",
      "cfead7ccebc84437b689ff207bb8d58b",
      "98aa40a24f94470c9de787489c4f338f",
      "041d650387ef4569805b73594b128c01",
      "10690ffc5c5046ba937e7d065404c56d",
      "718b67137729419f884bc242cdb06001",
      "8a50c4e5785b4dc58fb1c36406b2a676",
      "e0187c9d10f94ed19be8b0211d56e38e",
      "3f3e011616554f57bd80dbe126fae8e4",
      "fe32a6b5683c4b8cad90a093ebe95ad9",
      "e710eec922a54944a9ae8e1d53f12592",
      "de4368e5e6584123a8c018a925407d25",
      "f6045bfbc6ac4941bcaa99f5bc6d0ff3",
      "ef0cc3f41560485bad5036feb0f42d85",
      "0c17c1de3a6a4c67b3f20980b34aeea8",
      "86459f08abc34e319d878f86cb915718",
      "063087aa6e6e4c8b8d6292f34839d440",
      "5e18d148392b416e8c4e27a669fb3dd8",
      "1e0a5ca3323c4708934113a5c3e8f41c",
      "718e5b0213f342c595ea1eaaaae36091",
      "b1b9e9001b9448ee9b8546fd10203f55",
      "2749468eabb5412488eacac9107a0607",
      "3506e49904134b86ace33e2196aef75d",
      "2baf39b4415449b794bcd705730c0f7c",
      "5ceb845b4caf41a6b5f5904015952b33",
      "72628525eeee43df84d2d913df89d83a",
      "38d6a31d3c604b39959bc3675935b2cf",
      "e206a14cbaf14d7f8016f8e301532de4",
      "6aeb32384b7a493d85d475ac52e3030f",
      "1c2e8b3e55c84c4cae688dd38fb12373",
      "afa3d63b6e5345dbbce5983ba9818fc4",
      "6111283e30184ffda9e21c6f09e217c3",
      "7516aca38a834507bda383036610fc62"
     ]
    },
    "id": "2fkU5RB-_fWz",
    "outputId": "35554dbd-6859-45cf-dc03-fafc0461d87b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading datasets...\n",
      "Training set samples: 148966\n",
      "Validation set samples: 31818\n",
      "Test set samples: 31904\n",
      "\n",
      "Label distribution:\n",
      "Training set: effectiveness\n",
      "0    37081\n",
      "1    13254\n",
      "2    98631\n",
      "Name: count, dtype: int64\n",
      "Validation set: effectiveness\n",
      "0     7920\n",
      "1     2831\n",
      "2    21067\n",
      "Name: count, dtype: int64\n",
      "Test set: effectiveness\n",
      "0     7942\n",
      "1     2838\n",
      "2    21124\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Preprocessing text...\n",
      "\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa78f41b5194dd791a073c892c3bad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb2d45923344e76853d392a2c254130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4253643cb845428044fb3ea8dc6e96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4368e5e6584123a8c018a925407d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating datasets...\n",
      "\n",
      "Creating DataLoaders...\n",
      "\n",
      "Loading BERT model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3506e49904134b86ace33e2196aef75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting BERT model training...\n",
      "\n",
      "======== Epoch 1 / 4 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9311/9311 [27:32<00:00,  5.64it/s, loss=0.1634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.4944\n",
      "Validation Loss: 0.4077\n",
      "Validation Accuracy: 0.8435\n",
      "Saved new best model\n",
      "\n",
      "======== Epoch 2 / 4 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9311/9311 [27:21<00:00,  5.67it/s, loss=0.4478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.3349\n",
      "Validation Loss: 0.3714\n",
      "Validation Accuracy: 0.8729\n",
      "Saved new best model\n",
      "\n",
      "======== Epoch 3 / 4 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 9311/9311 [27:23<00:00,  5.67it/s, loss=0.0080]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.2238\n",
      "Validation Loss: 0.4050\n",
      "Validation Accuracy: 0.8900\n",
      "Saved new best model\n",
      "\n",
      "======== Epoch 4 / 4 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 74/9311 [00:13<27:23,  5.62it/s, loss=0.1055]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-de4ab1446ecc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-de4ab1446ecc>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting BERT model training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m     training_history, best_val_accuracy = train_model(\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-de4ab1446ecc>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, epochs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Set random seed to ensure reproducible results\n",
    "def set_seed(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess drug reviews\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Keep letters, numbers, common punctuation (preserving drug information)\n",
    "    text = re.sub(r'[^\\w\\s.,!?;:]', ' ', text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Create custom Dataset class\n",
    "class DrugReviewsDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len=256):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        # Process text using BERT tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Model training function\n",
    "def train_model(model, train_dataloader, val_dataloader, epochs=4):\n",
    "    # Optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "    # Calculate total training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Create learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # Record training history\n",
    "    training_history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_accuracy': []\n",
    "    }\n",
    "\n",
    "    # Record best validation accuracy\n",
    "    best_val_accuracy = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\n======== Epoch {epoch + 1} / {epochs} ========')\n",
    "\n",
    "        # Training mode\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        # Training progress bar\n",
    "        progress_bar = tqdm(train_dataloader, desc=\"Training\", position=0, leave=True)\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            # Load data to GPU\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Clear previous gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping to prevent gradient explosion\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update learning rate\n",
    "            scheduler.step()\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        # Calculate average training loss\n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "        training_history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy = evaluate_model(model, val_dataloader)\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            # Save model\n",
    "            torch.save(model.state_dict(), 'best_bert_model.pt')\n",
    "            print(\"Saved new best model\")\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_history['train_loss'], label='Training Loss')\n",
    "    plt.plot(training_history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(training_history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('bert_training_history.png')\n",
    "    plt.close()\n",
    "\n",
    "    return training_history, best_val_accuracy\n",
    "\n",
    "# Model evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # No gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Load data to GPU\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Get prediction results\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Test model and generate classification report\n",
    "def test_model(model, test_dataloader):\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # No gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Testing\"):\n",
    "            # Load data to GPU\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Get prediction results\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Generate classification report\n",
    "    target_names = ['Not Effective(0)', 'Moderately Effective(1)', 'Effective(2)']\n",
    "    report = classification_report(all_labels, all_preds,\n",
    "                                  target_names=target_names,\n",
    "                                  digits=3)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=target_names,\n",
    "               yticklabels=target_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('BERT Model Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('bert_confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Generate detailed classification report (dictionary form)\n",
    "    report_dict = classification_report(all_labels, all_preds,\n",
    "                                      target_names=target_names,\n",
    "                                      output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "    return accuracy, report_df, all_preds, all_labels\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Load datasets\n",
    "    def load_datasets(base_dir='/content/drive/MyDrive/text_analysis/datasets'):\n",
    "        print(\"Loading datasets...\")\n",
    "        train_path = os.path.join(base_dir, \"train_drug_reviews2.csv\")\n",
    "        val_path = os.path.join(base_dir, \"val_drug_reviews2.csv\")\n",
    "        test_path = os.path.join(base_dir, \"test_drug_reviews2.csv\")\n",
    "\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        val_df = pd.read_csv(val_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        # Select only needed columns\n",
    "        train_df = train_df[['review', 'effectiveness']]\n",
    "        val_df = val_df[['review', 'effectiveness']]\n",
    "        test_df = test_df[['review', 'effectiveness']]\n",
    "\n",
    "        # Check data distribution\n",
    "        print(f\"Training set samples: {len(train_df)}\")\n",
    "        print(f\"Validation set samples: {len(val_df)}\")\n",
    "        print(f\"Test set samples: {len(test_df)}\")\n",
    "\n",
    "        print(\"\\nLabel distribution:\")\n",
    "        print(\"Training set:\", train_df['effectiveness'].value_counts().sort_index())\n",
    "        print(\"Validation set:\", val_df['effectiveness'].value_counts().sort_index())\n",
    "        print(\"Test set:\", test_df['effectiveness'].value_counts().sort_index())\n",
    "\n",
    "        return train_df, val_df, test_df\n",
    "\n",
    "    # Load data\n",
    "    train_df, val_df, test_df = load_datasets()\n",
    "\n",
    "    # Preprocess text\n",
    "    print(\"\\nPreprocessing text...\")\n",
    "    train_df['processed_review'] = train_df['review'].apply(preprocess_text)\n",
    "    val_df['processed_review'] = val_df['review'].apply(preprocess_text)\n",
    "    test_df['processed_review'] = test_df['review'].apply(preprocess_text)\n",
    "\n",
    "    # Load BERT tokenizer\n",
    "    print(\"\\nLoading BERT tokenizer...\")\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Create datasets\n",
    "    print(\"\\nCreating datasets...\")\n",
    "    train_dataset = DrugReviewsDataset(\n",
    "        reviews=train_df['processed_review'].values,\n",
    "        labels=train_df['effectiveness'].values,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    val_dataset = DrugReviewsDataset(\n",
    "        reviews=val_df['processed_review'].values,\n",
    "        labels=val_df['effectiveness'].values,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    test_dataset = DrugReviewsDataset(\n",
    "        reviews=test_df['processed_review'].values,\n",
    "        labels=test_df['effectiveness'].values,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Create DataLoaders\n",
    "    print(\"\\nCreating DataLoaders...\")\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,  # Small batches can reduce memory requirements\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Calculate class weights (handling class imbalance)\n",
    "    class_counts = train_df['effectiveness'].value_counts().sort_index()\n",
    "    class_weights = 1.0 / torch.tensor(class_counts.values, dtype=torch.float)\n",
    "    class_weights = class_weights / class_weights.sum()\n",
    "    class_weights = class_weights.to(device)\n",
    "\n",
    "    # Load pre-trained BERT model\n",
    "    print(\"\\nLoading BERT model...\")\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=3,  # Three classes: 0, 1, 2\n",
    "        problem_type=\"single_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Move model to GPU\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Set weights\n",
    "    # Note: Some versions of transformers may not support directly setting class_weights\n",
    "    # If error occurs, consider manually weighting in loss function calculation\n",
    "\n",
    "    # Train model\n",
    "    print(\"\\nStarting BERT model training...\")\n",
    "    training_history, best_val_accuracy = train_model(\n",
    "        model=model,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        epochs=4  # BERT typically needs only a few epochs\n",
    "    )\n",
    "\n",
    "    # Load best model for testing\n",
    "    print(\"\\nLoading best model for testing...\")\n",
    "    model.load_state_dict(torch.load('best_bert_model.pt'))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating model on test set...\")\n",
    "    test_accuracy, report_df, all_preds, all_labels = test_model(\n",
    "        model=model,\n",
    "        test_dataloader=test_dataloader\n",
    "    )\n",
    "\n",
    "    print(\"\\nFinal results:\")\n",
    "    print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"\\nDetailed classification report:\")\n",
    "    print(report_df)\n",
    "\n",
    "    # Save prediction results (optional)\n",
    "    test_results = pd.DataFrame({\n",
    "        'review': test_df['review'],\n",
    "        'true_label': all_labels,\n",
    "        'predicted_label': all_preds\n",
    "    })\n",
    "    test_results.to_csv('bert_test_predictions.csv', index=False)\n",
    "\n",
    "    return model, test_accuracy, report_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYOMcWNvfVJF",
    "outputId": "acccf485-6573-4cca-9d23-1a93a5b444f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading test data from: /content/drive/MyDrive/text_analysis/datasets/test_drug_reviews2.csv\n",
      "Test set samples: 31904\n",
      "Label distribution: effectiveness\n",
      "0     7942\n",
      "1     2838\n",
      "2    21124\n",
      "Name: count, dtype: int64\n",
      "Preprocessing test data...\n",
      "Loading BERT tokenizer...\n",
      "Initializing model architecture...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model from: best_bert_model.pt\n",
      "Evaluating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 997/997 [02:10<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8865\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "       Not Effective(0)      0.863     0.850     0.856      7942\n",
      "Moderately Effective(1)      0.573     0.492     0.530      2838\n",
      "           Effective(2)      0.930     0.953     0.942     21124\n",
      "\n",
      "               accuracy                          0.887     31904\n",
      "              macro avg      0.789     0.765     0.776     31904\n",
      "           weighted avg      0.882     0.887     0.884     31904\n",
      "\n",
      "Saved prediction results to: bert_evaluation_results.csv\n",
      "\n",
      "Final Results:\n",
      "Test Accuracy: 0.8865\n",
      "\n",
      "Detailed Classification Report:\n",
      "                         precision    recall  f1-score       support\n",
      "Not Effective(0)          0.862898  0.849534  0.856164   7942.000000\n",
      "Moderately Effective(1)   0.573011  0.492248  0.529568   2838.000000\n",
      "Effective(2)              0.930337  0.953371  0.941713  21124.000000\n",
      "accuracy                  0.886503  0.886503  0.886503      0.886503\n",
      "macro avg                 0.788749  0.765051  0.775815  31904.000000\n",
      "weighted avg              0.881763  0.886503  0.883755  31904.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Text preprocessing function (same as in training)\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess drug reviews\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Keep letters, numbers, common punctuation (preserving drug information)\n",
    "    text = re.sub(r'[^\\w\\s.,!?;:]', ' ', text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Dataset class (same as in training)\n",
    "class DrugReviewsDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len=256):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        # Process text using BERT tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Test model and generate classification report\n",
    "def test_model(model, test_dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on the test dataset\n",
    "\n",
    "    Args:\n",
    "        model: The trained BERT model\n",
    "        test_dataloader: DataLoader containing the test dataset\n",
    "\n",
    "    Returns:\n",
    "        accuracy: Test accuracy\n",
    "        report_df: DataFrame with detailed classification metrics\n",
    "        all_preds: List of model predictions\n",
    "        all_labels: List of true labels\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # No gradient calculation needed for evaluation\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Testing\"):\n",
    "            # Load data to device (CPU or GPU)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Get prediction results\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Generate classification report\n",
    "    target_names = ['Not Effective(0)', 'Moderately Effective(1)', 'Effective(2)']\n",
    "    report = classification_report(all_labels, all_preds,\n",
    "                                  target_names=target_names,\n",
    "                                  digits=3)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=target_names,\n",
    "               yticklabels=target_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('BERT Model Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('bert_evaluation_confusion_matrix.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Generate detailed classification report (dictionary form)\n",
    "    report_dict = classification_report(all_labels, all_preds,\n",
    "                                      target_names=target_names,\n",
    "                                      output_dict=True)\n",
    "    report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "    return accuracy, report_df, all_preds, all_labels\n",
    "\n",
    "def evaluate_saved_model(model_path, test_data_path):\n",
    "    \"\"\"\n",
    "    Load a saved model and evaluate it on test data\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to the saved model file\n",
    "        test_data_path: Path to the test CSV file\n",
    "\n",
    "    Returns:\n",
    "        test_accuracy: Accuracy on test set\n",
    "        report_df: Detailed classification report\n",
    "    \"\"\"\n",
    "    print(f\"Loading test data from: {test_data_path}\")\n",
    "\n",
    "    # Load test dataset\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "    test_df = test_df[['review', 'effectiveness']]  # Select only needed columns\n",
    "\n",
    "    print(f\"Test set samples: {len(test_df)}\")\n",
    "    print(f\"Label distribution: {test_df['effectiveness'].value_counts().sort_index()}\")\n",
    "\n",
    "    # Preprocess text\n",
    "    print(\"Preprocessing test data...\")\n",
    "    test_df['processed_review'] = test_df['review'].apply(preprocess_text)\n",
    "\n",
    "    # Load BERT tokenizer\n",
    "    print(\"Loading BERT tokenizer...\")\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Create test dataset\n",
    "    test_dataset = DrugReviewsDataset(\n",
    "        reviews=test_df['processed_review'].values,\n",
    "        labels=test_df['effectiveness'].values,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Create DataLoader\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Initialize model architecture\n",
    "    print(\"Initializing model architecture...\")\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        'bert-base-uncased',\n",
    "        num_labels=3,  # Three classes: 0, 1, 2\n",
    "        problem_type=\"single_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Load saved weights\n",
    "    print(f\"Loading saved model from: {model_path}\")\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Evaluate model\n",
    "    print(\"Evaluating model...\")\n",
    "    test_accuracy, report_df, all_preds, all_labels = test_model(\n",
    "        model=model,\n",
    "        test_dataloader=test_dataloader\n",
    "    )\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame({\n",
    "        'review': test_df['review'],\n",
    "        'true_label': all_labels,\n",
    "        'predicted_label': all_preds\n",
    "    })\n",
    "\n",
    "    results_path = 'bert_evaluation_results.csv'\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    print(f\"Saved prediction results to: {results_path}\")\n",
    "\n",
    "    return test_accuracy, report_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths\n",
    "    model_path = 'best_bert_model.pt'  # Path to saved model\n",
    "    test_data_path = '/content/drive/MyDrive/text_analysis/datasets/test_drug_reviews2.csv'  # Path to test data\n",
    "\n",
    "    # Run evaluation\n",
    "    test_accuracy, report_df = evaluate_saved_model(model_path, test_data_path)\n",
    "\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyD3hpDGigi_",
    "outputId": "960f12fb-2458-47d7-9839-3e0d1c5cc7a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading test data from: /content/drive/MyDrive/text_analysis/datasets/test_drug_reviews2.csv\n",
      "Test set samples: 31904\n",
      "Label distribution: effectiveness\n",
      "0     7942\n",
      "1     2838\n",
      "2    21124\n",
      "Name: count, dtype: int64\n",
      "Preprocessing test data...\n",
      "Loading BERT tokenizer...\n",
      "Initializing model architecture with attention outputs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained weights from best_bert_model.pt\n",
      "Evaluating model and extracting attention...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating accuracy:   0%|          | 0/1994 [00:00<?, ?it/s]BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Evaluating accuracy: 100%|██████████| 1994/1994 [02:25<00:00, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8865\n",
      "\n",
      "Classification Report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "       Not Effective(0)      0.863     0.850     0.856      7942\n",
      "Moderately Effective(1)      0.573     0.492     0.530      2838\n",
      "           Effective(2)      0.930     0.953     0.942     21124\n",
      "\n",
      "               accuracy                          0.887     31904\n",
      "              macro avg      0.789     0.765     0.776     31904\n",
      "           weighted avg      0.882     0.887     0.884     31904\n",
      "\n",
      "\n",
      "Extracting token importance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting attention: 100%|██████████| 1994/1994 [04:33<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 Important Tokens:\n",
      "           Token  Importance\n",
      "0      suspended    0.121173\n",
      "1          greed    0.118603\n",
      "2     delightful    0.084953\n",
      "3            uta    0.083168\n",
      "4         dieter    0.080312\n",
      "5           ohio    0.078077\n",
      "6         coward    0.078074\n",
      "7         carole    0.078070\n",
      "8          roche    0.076103\n",
      "9    netherlands    0.074857\n",
      "10     vancouver    0.074343\n",
      "11       mapping    0.071492\n",
      "12        cheryl    0.071328\n",
      "13     excellent    0.070921\n",
      "14   exceptional    0.069072\n",
      "15          iowa    0.068792\n",
      "16      zimbabwe    0.066827\n",
      "17     celebrate    0.066560\n",
      "18  recognizable    0.066176\n",
      "19          katy    0.065271\n",
      "Saved top tokens to: bert_attention_outputs/top_important_tokens.csv\n",
      "\n",
      "Visualizing sample attention patterns...\n",
      "\n",
      "Final Results:\n",
      "Test Accuracy: 0.8865\n",
      "\n",
      "Top 20 Important Tokens:\n",
      "           Token  Importance\n",
      "0      suspended    0.121173\n",
      "1          greed    0.118603\n",
      "2     delightful    0.084953\n",
      "3            uta    0.083168\n",
      "4         dieter    0.080312\n",
      "5           ohio    0.078077\n",
      "6         coward    0.078074\n",
      "7         carole    0.078070\n",
      "8          roche    0.076103\n",
      "9    netherlands    0.074857\n",
      "10     vancouver    0.074343\n",
      "11       mapping    0.071492\n",
      "12        cheryl    0.071328\n",
      "13     excellent    0.070921\n",
      "14   exceptional    0.069072\n",
      "15          iowa    0.068792\n",
      "16      zimbabwe    0.066827\n",
      "17     celebrate    0.066560\n",
      "18  recognizable    0.066176\n",
      "19          katy    0.065271\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.cm as cm\n",
    "from IPython.display import HTML, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Text preprocessing function (same as in training)\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess drug reviews\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Keep letters, numbers, common punctuation (preserving drug information)\n",
    "    text = re.sub(r'[^\\w\\s.,!?;:]', ' ', text)\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Dataset class with attention output flag\n",
    "class DrugReviewsDataset(Dataset):\n",
    "    def __init__(self, reviews, labels, tokenizer, max_len=256):\n",
    "        self.reviews = reviews\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = str(self.reviews[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        # Process text using BERT tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Custom BERT model to extract attention weights\n",
    "class BertWithAttention(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Custom BERT model that returns attention weights along with predictions\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path=None, num_labels=3):\n",
    "        super(BertWithAttention, self).__init__()\n",
    "\n",
    "        # If model path is provided, we'll load it later\n",
    "        self.model_path = model_path\n",
    "\n",
    "        # Initialize model configuration\n",
    "        config = BertConfig.from_pretrained(\n",
    "            'bert-base-uncased',\n",
    "            num_labels=num_labels,\n",
    "            output_attentions=True  # Set this to get attention weights\n",
    "        )\n",
    "\n",
    "        # Initialize BERT with the configuration\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(\n",
    "            'bert-base-uncased',\n",
    "            config=config\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        \"\"\"\n",
    "        Forward pass that returns both outputs and attention weights\n",
    "        \"\"\"\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels,\n",
    "            output_attentions=True  # Ensure attention outputs\n",
    "        )\n",
    "\n",
    "        # Return all outputs for further processing\n",
    "        return outputs\n",
    "\n",
    "    def load_trained_weights(self):\n",
    "        \"\"\"\n",
    "        Load weights from a trained model file\n",
    "        \"\"\"\n",
    "        if self.model_path:\n",
    "            # Load model weights into the BERT model\n",
    "            state_dict = torch.load(self.model_path, map_location=device)\n",
    "            self.bert.load_state_dict(state_dict)\n",
    "            print(f\"Loaded trained weights from {self.model_path}\")\n",
    "\n",
    "# Function to extract attention importance\n",
    "def extract_attention_importance(model, dataloader, tokenizer, top_k=20):\n",
    "    \"\"\"\n",
    "    Extract and aggregate attention weights to find important tokens\n",
    "\n",
    "    Args:\n",
    "        model: The BERT model with attention output\n",
    "        dataloader: DataLoader with the dataset\n",
    "        tokenizer: BERT tokenizer for decoding tokens\n",
    "        top_k: Number of top tokens to identify\n",
    "\n",
    "    Returns:\n",
    "        word_importance_df: DataFrame with top important words and scores\n",
    "        sample_attentions: Dictionary of sample reviews with their attention weights\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Store aggregated attention scores for unique tokens\n",
    "    token_attention_scores = {}\n",
    "\n",
    "    # Store sample reviews with attention for visualization\n",
    "    sample_attentions = {}\n",
    "\n",
    "    # Process batches to extract attention\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(dataloader, desc=\"Extracting attention\")):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            reviews = batch['review_text']\n",
    "\n",
    "            # Forward pass to get attention weights\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            # Extract attention weights - shape is [batch_size, num_heads, seq_len, seq_len]\n",
    "            # We get attention from the last layer (closest to classification decision)\n",
    "            attentions = outputs.attentions[-1]  # Last layer's attention\n",
    "\n",
    "            # Average over attention heads\n",
    "            attentions = attentions.mean(dim=1)  # Now shape is [batch_size, seq_len, seq_len]\n",
    "\n",
    "            # Process each sample in the batch\n",
    "            for sample_idx in range(input_ids.size(0)):\n",
    "                review = reviews[sample_idx]\n",
    "\n",
    "                # Get tokens for this sample\n",
    "                tokens = tokenizer.convert_ids_to_tokens(input_ids[sample_idx])\n",
    "\n",
    "                # Get attention for this sample - we look at attention from CLS token (first token)\n",
    "                # This shows how much the CLS token attends to each other token when making classification\n",
    "                token_attn = attentions[sample_idx, 0, :].cpu().numpy()  # Attention from CLS token\n",
    "\n",
    "                # Store a few samples for visualization\n",
    "                if batch_idx < 3 and sample_idx < 3:\n",
    "                    # Store only the tokens that have attention mask of 1 (not padding)\n",
    "                    mask = batch['attention_mask'][sample_idx].cpu().numpy()\n",
    "                    valid_tokens = [t for i, t in enumerate(tokens) if mask[i] == 1]\n",
    "                    valid_attention = token_attn[:len(valid_tokens)]\n",
    "\n",
    "                    sample_attentions[f\"sample_{batch_idx}_{sample_idx}\"] = {\n",
    "                        \"review\": review,\n",
    "                        \"tokens\": valid_tokens,\n",
    "                        \"attention\": valid_attention\n",
    "                    }\n",
    "\n",
    "                # Aggregate attention scores for each unique token\n",
    "                for i, token in enumerate(tokens):\n",
    "                    if token in ['[PAD]', '[CLS]', '[SEP]']:\n",
    "                        continue  # Skip special tokens\n",
    "\n",
    "                    # Attention score from CLS to this token\n",
    "                    score = token_attn[i]\n",
    "\n",
    "                    # Aggregate scores for unique tokens\n",
    "                    if token in token_attention_scores:\n",
    "                        token_attention_scores[token].append(score)\n",
    "                    else:\n",
    "                        token_attention_scores[token] = [score]\n",
    "\n",
    "    # Compute average attention for each token\n",
    "    token_avg_attention = {\n",
    "        token: np.mean(scores)\n",
    "        for token, scores in token_attention_scores.items()\n",
    "    }\n",
    "\n",
    "    # Merge subword tokens (those starting with ##)\n",
    "    merged_token_attention = {}\n",
    "    for token, score in token_avg_attention.items():\n",
    "        if token.startswith('##'):\n",
    "            # Find the previous token and merge\n",
    "            prefix = list(merged_token_attention.keys())[-1] if merged_token_attention else None\n",
    "            if prefix:\n",
    "                merged_token = prefix + token[2:]  # Remove ## and concatenate\n",
    "                merged_score = (merged_token_attention[prefix] + score) / 2  # Average score\n",
    "\n",
    "                # Update with merged token and remove the prefix\n",
    "                merged_token_attention.pop(prefix)\n",
    "                merged_token_attention[merged_token] = merged_score\n",
    "            else:\n",
    "                merged_token_attention[token] = score\n",
    "        else:\n",
    "            merged_token_attention[token] = score\n",
    "\n",
    "    # Sort by attention score and get top k\n",
    "    sorted_tokens = sorted(merged_token_attention.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_tokens = sorted_tokens[:top_k]\n",
    "\n",
    "    # Create DataFrame for visualization\n",
    "    word_importance_df = pd.DataFrame(top_tokens, columns=['Token', 'Importance'])\n",
    "\n",
    "    return word_importance_df, sample_attentions\n",
    "\n",
    "# Function to visualize attention for a sample\n",
    "def visualize_attention(sample_data, title=\"Attention Visualization\", save_path=None):\n",
    "    \"\"\"\n",
    "    Create a visualization of token attention weights\n",
    "\n",
    "    Args:\n",
    "        sample_data: Dictionary with tokens and their attention weights\n",
    "        title: Title for the visualization\n",
    "        save_path: Path to save the visualization (if None, just display)\n",
    "    \"\"\"\n",
    "    tokens = sample_data[\"tokens\"]\n",
    "    attention = sample_data[\"attention\"]\n",
    "    review = sample_data[\"review\"]\n",
    "\n",
    "    # Limit to non-padding tokens\n",
    "    if len(tokens) > len(attention):\n",
    "        tokens = tokens[:len(attention)]\n",
    "\n",
    "    # Skip special tokens at the beginning and end ([CLS] and [SEP])\n",
    "    tokens = tokens[1:-1]\n",
    "    attention = attention[1:-1]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot bars for attention weights\n",
    "    plt.bar(range(len(tokens)), attention, color=cm.viridis(attention / max(attention)))\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.xticks(range(len(tokens)), tokens, rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"Tokens\")\n",
    "    plt.ylabel(\"Attention Weight\")\n",
    "    plt.title(f\"{title}\\nReview: {review[:100]}...\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Function to visualize top important tokens\n",
    "def visualize_top_tokens(word_importance_df, title=\"Top Important Tokens\", save_path=None):\n",
    "    \"\"\"\n",
    "    Create a visualization of top important tokens\n",
    "\n",
    "    Args:\n",
    "        word_importance_df: DataFrame with tokens and their importance scores\n",
    "        title: Title for the visualization\n",
    "        save_path: Path to save the visualization (if None, just display)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Create horizontal bar chart\n",
    "    bars = plt.barh(\n",
    "        range(len(word_importance_df)),\n",
    "        word_importance_df['Importance'],\n",
    "        color=cm.viridis(word_importance_df['Importance'] / word_importance_df['Importance'].max())\n",
    "    )\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.yticks(range(len(word_importance_df)), word_importance_df['Token'])\n",
    "    plt.xlabel(\"Average Attention Weight\")\n",
    "    plt.title(title)\n",
    "    plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# Function to create colored text based on attention weights\n",
    "def attention_html(tokens, attention):\n",
    "    \"\"\"\n",
    "    Create HTML with colored text based on attention weights\n",
    "\n",
    "    Args:\n",
    "        tokens: List of tokens\n",
    "        attention: Attention weights for each token\n",
    "\n",
    "    Returns:\n",
    "        HTML representation of colored text\n",
    "    \"\"\"\n",
    "    html = \"\"\n",
    "\n",
    "    # Normalize attention to [0, 1] for coloring\n",
    "    if max(attention) > 0:\n",
    "        attention = attention / max(attention)\n",
    "\n",
    "    for token, attn in zip(tokens, attention):\n",
    "        if token.startswith(\"##\"):\n",
    "            token = token[2:]  # Remove ## prefix for subwords\n",
    "            space = \"\"  # No space for subword pieces\n",
    "        else:\n",
    "            space = \" \"  # Add space between words\n",
    "\n",
    "        # Skip special tokens\n",
    "        if token in [\"[CLS]\", \"[SEP]\", \"[PAD]\"]:\n",
    "            continue\n",
    "\n",
    "        # Get color intensity based on attention score\n",
    "        r = int(255 * attn)\n",
    "        g = int(100 * (1 - attn))\n",
    "        b = int(100 * (1 - attn))\n",
    "\n",
    "        html += f'{space}<span style=\"background-color:rgba({r},{g},{b},0.3)\">{token}</span>'\n",
    "\n",
    "    return html\n",
    "\n",
    "# Main evaluation function\n",
    "def evaluate_and_explain(model_path, test_data_path, output_dir=\"bert_attention_outputs\"):\n",
    "    \"\"\"\n",
    "    Load a saved model, evaluate it, and extract attention-based feature importance\n",
    "\n",
    "    Args:\n",
    "        model_path: Path to the saved model file\n",
    "        test_data_path: Path to the test CSV file\n",
    "        output_dir: Directory to save outputs\n",
    "\n",
    "    Returns:\n",
    "        test_accuracy: Accuracy on test set\n",
    "        top_tokens_df: DataFrame with top important tokens\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Loading test data from: {test_data_path}\")\n",
    "\n",
    "    # Load test dataset\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "    test_df = test_df[['review', 'effectiveness']]  # Select only needed columns\n",
    "\n",
    "    print(f\"Test set samples: {len(test_df)}\")\n",
    "    print(f\"Label distribution: {test_df['effectiveness'].value_counts().sort_index()}\")\n",
    "\n",
    "    # Preprocess text\n",
    "    print(\"Preprocessing test data...\")\n",
    "    test_df['processed_review'] = test_df['review'].apply(preprocess_text)\n",
    "\n",
    "    # Load BERT tokenizer\n",
    "    print(\"Loading BERT tokenizer...\")\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Create test dataset\n",
    "    test_dataset = DrugReviewsDataset(\n",
    "        reviews=test_df['processed_review'].values,\n",
    "        labels=test_df['effectiveness'].values,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Create DataLoader\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,  # Smaller batch size for attention analysis\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Initialize custom BERT model with attention outputs\n",
    "    print(\"Initializing model architecture with attention outputs...\")\n",
    "    model = BertWithAttention(model_path=model_path, num_labels=3)\n",
    "    model.load_trained_weights()\n",
    "\n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Evaluate model\n",
    "    print(\"Evaluating model and extracting attention...\")\n",
    "\n",
    "    # Run standard evaluation\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Evaluate accuracy\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Evaluating accuracy\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Get prediction results\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Generate classification report\n",
    "    target_names = ['Not Effective(0)', 'Moderately Effective(1)', 'Effective(2)']\n",
    "    report = classification_report(all_labels, all_preds,\n",
    "                                  target_names=target_names,\n",
    "                                  digits=3)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    # Extract attention importance\n",
    "    print(\"\\nExtracting token importance...\")\n",
    "    top_tokens_df, sample_attentions = extract_attention_importance(\n",
    "        model=model,\n",
    "        dataloader=test_dataloader,\n",
    "        tokenizer=tokenizer,\n",
    "        top_k=20\n",
    "    )\n",
    "\n",
    "    # Print top tokens\n",
    "    print(\"\\nTop 20 Important Tokens:\")\n",
    "    print(top_tokens_df)\n",
    "\n",
    "    # Save top tokens to CSV\n",
    "    top_tokens_path = os.path.join(output_dir, \"top_important_tokens.csv\")\n",
    "    top_tokens_df.to_csv(top_tokens_path, index=False)\n",
    "    print(f\"Saved top tokens to: {top_tokens_path}\")\n",
    "\n",
    "    # Visualize top tokens\n",
    "    visualize_top_tokens(\n",
    "        top_tokens_df,\n",
    "        title=\"Top 20 Important Tokens for BERT Drug Effectiveness Classification\",\n",
    "        save_path=os.path.join(output_dir, \"top_tokens_visualization.png\")\n",
    "    )\n",
    "\n",
    "    # Visualize sample attention patterns\n",
    "    print(\"\\nVisualizing sample attention patterns...\")\n",
    "    for i, (sample_key, sample_data) in enumerate(sample_attentions.items()):\n",
    "        # Visualize attention weights\n",
    "        visualize_attention(\n",
    "            sample_data,\n",
    "            title=f\"Sample {i+1} Attention Weights\",\n",
    "            save_path=os.path.join(output_dir, f\"sample_{i+1}_attention.png\")\n",
    "        )\n",
    "\n",
    "        # Create colored text HTML\n",
    "        tokens = sample_data[\"tokens\"]\n",
    "        attention = sample_data[\"attention\"]\n",
    "        review = sample_data[\"review\"]\n",
    "\n",
    "        html_content = f\"\"\"\n",
    "        <h3>Sample {i+1} Review:</h3>\n",
    "        <p><b>Original:</b> {review[:300]}...</p>\n",
    "        <p><b>Attention Highlighted:</b> {attention_html(tokens, attention)}</p>\n",
    "        <hr>\n",
    "        \"\"\"\n",
    "\n",
    "        # Save HTML visualization\n",
    "        with open(os.path.join(output_dir, f\"sample_{i+1}_highlighted.html\"), \"w\") as f:\n",
    "            f.write(html_content)\n",
    "\n",
    "    # Generate class-specific important tokens (if time allows)\n",
    "\n",
    "    return test_accuracy, top_tokens_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set paths\n",
    "    model_path = 'best_bert_model.pt'  # Path to saved model\n",
    "    test_data_path = '/content/drive/MyDrive/text_analysis/datasets/test_drug_reviews2.csv'  # Path to test data\n",
    "    output_dir = 'bert_attention_outputs'  # Directory to save outputs\n",
    "\n",
    "    # Run evaluation with attention analysis\n",
    "    test_accuracy, top_tokens_df = evaluate_and_explain(\n",
    "        model_path=model_path,\n",
    "        test_data_path=test_data_path,\n",
    "        output_dir=output_dir\n",
    "    )\n",
    "\n",
    "    print(\"\\nFinal Results:\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(\"\\nTop 20 Important Tokens:\")\n",
    "    print(top_tokens_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "041d650387ef4569805b73594b128c01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe32a6b5683c4b8cad90a093ebe95ad9",
      "placeholder": "​",
      "style": "IPY_MODEL_e710eec922a54944a9ae8e1d53f12592",
      "value": " 466k/466k [00:00&lt;00:00, 699kB/s]"
     }
    },
    "063087aa6e6e4c8b8d6292f34839d440": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0804f1c600bc4cf5832b394149c4e560": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0494803d10e4097823aca85d4f40186",
      "placeholder": "​",
      "style": "IPY_MODEL_9f37e28c1bba4eaa8e3793573e45cdae",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "0c17c1de3a6a4c67b3f20980b34aeea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1b9e9001b9448ee9b8546fd10203f55",
      "placeholder": "​",
      "style": "IPY_MODEL_2749468eabb5412488eacac9107a0607",
      "value": " 570/570 [00:00&lt;00:00, 70.3kB/s]"
     }
    },
    "10690ffc5c5046ba937e7d065404c56d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c2e8b3e55c84c4cae688dd38fb12373": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e0a5ca3323c4708934113a5c3e8f41c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2749468eabb5412488eacac9107a0607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2baf39b4415449b794bcd705730c0f7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e206a14cbaf14d7f8016f8e301532de4",
      "placeholder": "​",
      "style": "IPY_MODEL_6aeb32384b7a493d85d475ac52e3030f",
      "value": "model.safetensors: 100%"
     }
    },
    "3506e49904134b86ace33e2196aef75d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2baf39b4415449b794bcd705730c0f7c",
       "IPY_MODEL_5ceb845b4caf41a6b5f5904015952b33",
       "IPY_MODEL_72628525eeee43df84d2d913df89d83a"
      ],
      "layout": "IPY_MODEL_38d6a31d3c604b39959bc3675935b2cf"
     }
    },
    "383f11dd9e0643e9a0e4238499dd0fc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "38d6a31d3c604b39959bc3675935b2cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c96119d7e3b4969af5d555f1aaf4988": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3cbe715b2d0f410f89c91c18f737ca98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f3e011616554f57bd80dbe126fae8e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "41ba3ea00b03450f9ec421d11c5677ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54b90a28ef75450a8508e5ee914ce1c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "576ce0fa13794cd599590361f3afd1bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5bf83774eb97475bafb30bbbbd7b62b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_383f11dd9e0643e9a0e4238499dd0fc5",
      "placeholder": "​",
      "style": "IPY_MODEL_3c96119d7e3b4969af5d555f1aaf4988",
      "value": "vocab.txt: 100%"
     }
    },
    "5c01760a89844a0abf3f7879b96fb8af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ceb845b4caf41a6b5f5904015952b33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c2e8b3e55c84c4cae688dd38fb12373",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afa3d63b6e5345dbbce5983ba9818fc4",
      "value": 440449768
     }
    },
    "5e18d148392b416e8c4e27a669fb3dd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6111283e30184ffda9e21c6f09e217c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aeb32384b7a493d85d475ac52e3030f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "718b67137729419f884bc242cdb06001": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "718e5b0213f342c595ea1eaaaae36091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "72628525eeee43df84d2d913df89d83a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6111283e30184ffda9e21c6f09e217c3",
      "placeholder": "​",
      "style": "IPY_MODEL_7516aca38a834507bda383036610fc62",
      "value": " 440M/440M [00:00&lt;00:00, 464MB/s]"
     }
    },
    "748070220fba41e98ca66bcb0b433997": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7516aca38a834507bda383036610fc62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f77e4abc6d844a1b2ca582ff71dd3e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86459f08abc34e319d878f86cb915718": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a43d8db896444c6ab4b7d5b881e804b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c01760a89844a0abf3f7879b96fb8af",
      "placeholder": "​",
      "style": "IPY_MODEL_90199ad5ea9c4c27acff500f2fc2699b",
      "value": " 48.0/48.0 [00:00&lt;00:00, 5.55kB/s]"
     }
    },
    "8a50c4e5785b4dc58fb1c36406b2a676": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8aa78f41b5194dd791a073c892c3bad1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0804f1c600bc4cf5832b394149c4e560",
       "IPY_MODEL_bf143d7fa2f140d8b7ac8b85a85d8231",
       "IPY_MODEL_8a43d8db896444c6ab4b7d5b881e804b"
      ],
      "layout": "IPY_MODEL_7f77e4abc6d844a1b2ca582ff71dd3e1"
     }
    },
    "90199ad5ea9c4c27acff500f2fc2699b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98aa40a24f94470c9de787489c4f338f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0187c9d10f94ed19be8b0211d56e38e",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3f3e011616554f57bd80dbe126fae8e4",
      "value": 466062
     }
    },
    "9f37e28c1bba4eaa8e3793573e45cdae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "afa3d63b6e5345dbbce5983ba9818fc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b0494803d10e4097823aca85d4f40186": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1b9e9001b9448ee9b8546fd10203f55": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf143d7fa2f140d8b7ac8b85a85d8231": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccd72515cd8f4936aa0a86b051f2e65c",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3cbe715b2d0f410f89c91c18f737ca98",
      "value": 48
     }
    },
    "ccd72515cd8f4936aa0a86b051f2e65c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfead7ccebc84437b689ff207bb8d58b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_718b67137729419f884bc242cdb06001",
      "placeholder": "​",
      "style": "IPY_MODEL_8a50c4e5785b4dc58fb1c36406b2a676",
      "value": "tokenizer.json: 100%"
     }
    },
    "d9f7921c1280435a957d5c4ed6b293ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54b90a28ef75450a8508e5ee914ce1c4",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f6c47c46c9044cd88f4c18e0a2fd2b95",
      "value": 231508
     }
    },
    "ddb2d45923344e76853d392a2c254130": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5bf83774eb97475bafb30bbbbd7b62b6",
       "IPY_MODEL_d9f7921c1280435a957d5c4ed6b293ec",
       "IPY_MODEL_f4d49a9063324385a2470fe6b652f439"
      ],
      "layout": "IPY_MODEL_748070220fba41e98ca66bcb0b433997"
     }
    },
    "de4368e5e6584123a8c018a925407d25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6045bfbc6ac4941bcaa99f5bc6d0ff3",
       "IPY_MODEL_ef0cc3f41560485bad5036feb0f42d85",
       "IPY_MODEL_0c17c1de3a6a4c67b3f20980b34aeea8"
      ],
      "layout": "IPY_MODEL_86459f08abc34e319d878f86cb915718"
     }
    },
    "e0187c9d10f94ed19be8b0211d56e38e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e206a14cbaf14d7f8016f8e301532de4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e710eec922a54944a9ae8e1d53f12592": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec4253643cb845428044fb3ea8dc6e96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfead7ccebc84437b689ff207bb8d58b",
       "IPY_MODEL_98aa40a24f94470c9de787489c4f338f",
       "IPY_MODEL_041d650387ef4569805b73594b128c01"
      ],
      "layout": "IPY_MODEL_10690ffc5c5046ba937e7d065404c56d"
     }
    },
    "ef0cc3f41560485bad5036feb0f42d85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e0a5ca3323c4708934113a5c3e8f41c",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_718e5b0213f342c595ea1eaaaae36091",
      "value": 570
     }
    },
    "f4d49a9063324385a2470fe6b652f439": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41ba3ea00b03450f9ec421d11c5677ed",
      "placeholder": "​",
      "style": "IPY_MODEL_576ce0fa13794cd599590361f3afd1bd",
      "value": " 232k/232k [00:00&lt;00:00, 15.6MB/s]"
     }
    },
    "f6045bfbc6ac4941bcaa99f5bc6d0ff3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_063087aa6e6e4c8b8d6292f34839d440",
      "placeholder": "​",
      "style": "IPY_MODEL_5e18d148392b416e8c4e27a669fb3dd8",
      "value": "config.json: 100%"
     }
    },
    "f6c47c46c9044cd88f4c18e0a2fd2b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe32a6b5683c4b8cad90a093ebe95ad9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
